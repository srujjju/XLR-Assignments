# -*- coding: utf-8 -*-
"""KNN Assignment_Zoo

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hNoYqKLM5_aAe0UBRVcOvVpLfJCWYLe2
"""

from google.colab import files

uploaded = files.upload()

import pandas as pd
file = pd.read_csv('Zoo.csv')
file.head()

X = file.iloc[:,:-1]
Y = file.iloc[:,-1]

import seaborn as sns
import matplotlib.pyplot as plt

sns.pairplot(file)
plt.show()

# Calculate correlation matrix
correlation_matrix = file.corr()

# Visualize correlation matrix using heatmap
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.show()

from sklearn.preprocessing import LabelEncoder
LR = LabelEncoder()

X['animal name'] = LR.fit_transform(X['animal name'])
X.head()

X.isnull().sum()

import numpy as np

sns.boxplot(data=X)
plt.show()
X.head()

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

def replace_outliers_with_median(df, columns):
    for column in columns:
        median = df[column].median()  # Compute median from the original DataFrame
        IQR = df[column].quantile(0.75) - df[column].quantile(0.25)
        lower_limit = df[column].quantile(0.25) - 1.5 * IQR
        upper_limit = df[column].quantile(0.75) + 1.5 * IQR
        df[column] = np.where(
            (df[column] < lower_limit) | (df[column] > upper_limit),
            median,  # Use the computed median
            df[column]
        )
    return df

# Assuming X_SS is your DataFrame and X_SS.columns are the columns you want to process
X = replace_outliers_with_median(X, X.columns)

# Plot boxplots to visualize the effect of outlier replacement
sns.boxplot(data=X)
plt.show()

# Display the head and tail of the DataFrame to see the changes
print(X.head())
print(X.tail())

from sklearn.linear_model import Lasso, Ridge
ridge = Ridge(alpha=2.0)
ridge.fit(X, Y)
print("Ridge coefficients:", ridge.coef_)


lasso = Lasso(alpha=0.01)
lasso.fit(X, Y)
print("Lasso coefficients:", lasso.coef_)

import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor as vif

vif_data = pd.DataFrame()
vif_data["features"] = X.columns
vif_data["VIF Factor"] = [vif(X.values, i) for i in range(X.shape[1])]

print(vif_data)

X = X.drop(['hair','eggs','milk',], axis=1)
X.head()

from sklearn.model_selection  import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3)
from sklearn.neighbors import KNeighborsClassifier
df = KNeighborsClassifier()
df.fit(x_train,y_train)
y_pred_train = df.predict(x_train)
y_pred_test = df.predict(x_test)

from sklearn.metrics import r2_score, log_loss,accuracy_score


r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)

print("R2 score (train):", r2_train)
print("R2 score (test):", r2_test)

from sklearn.metrics import r2_score, log_loss,accuracy_score


r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)

print("R2 score (train):", r2_train)
print("R2 score (test):", r2_test)

training_accuracies = []
test_accuracies = []
KNN = KNeighborsClassifier()
for i in range(1,101):
    X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.3, random_state=i)
    KNN.fit(X_train,Y_train)
    Y_pred_train  = KNN.predict(X_train)
    Y_pred_test   = KNN.predict(X_test)
    training_accuracies.append(accuracy_score(Y_train,Y_pred_train))
    test_accuracies.append(accuracy_score(Y_test,Y_pred_test))

print("Cross validation Training Accuracy: ",np.mean(training_accuracies).round(2))
print("Cross validation Test Accuracy: ",np.mean(test_accuracies).round(2))