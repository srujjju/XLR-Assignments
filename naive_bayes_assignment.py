# -*- coding: utf-8 -*-
"""Naive Bayes Assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ReDy1MWFr0ld_Gz33FYgD-gHvoPIJ-1D
"""

from google.colab import files

uploaded = files.upload()

import pandas as pd
file = pd.read_csv('SalaryData_Train.csv')
file.head()

X = file.iloc[:,:-1]
Y = file.iloc[:,-1]
X.head()

from sklearn.preprocessing import StandardScaler,LabelEncoder
SS = StandardScaler()
LR = LabelEncoder()
selected_columns_ss = ['age','educationno','capitalgain','capitalloss','hoursperweek']
selected_columns_lr = ['workclass','education','maritalstatus','maritalstatus','maritalstatus','race','sex','native','occupation','relationship']
X[selected_columns_ss] = SS.fit_transform(X[selected_columns_ss])
for column in selected_columns_lr:
  X[column] = LR.fit_transform(X[column])
print(X.head())

import numpy as np

X.isnull().sum()

# Calculate the median of Y, ignoring NaN values
median_y = np.nanmedian(Y)

# Replace NaN values in Y with the median
Y[np.isnan(Y)] = median_y
Y = pd.DataFrame(Y)
Y.isnull().sum()
Y

import seaborn as sns
import matplotlib.pyplot as plt
sns.pairplot(X)
plt.show()

# Calculate correlation matrix
correlation_matrix = file.corr()
correlation_matrix
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.show()

sns.boxplot(data=X)
plt.show()
X.head()

import numpy as np
def replace_outliers_with_median(df, columns):
  for column in columns:
    IQR = df[column].quantile(0.75) - df[column].quantile(0.25)
    lower_limit = df[column].quantile(0.25) - 1.5 * IQR
    upper_limit = df[column].quantile(0.75) + 1.5 * IQR
    df[column] = np.where(
        (df[column] < lower_limit) | (df[column] > upper_limit),
        df[column].median(),
        df[column]
    )
  return df

X = replace_outliers_with_median(X, X.columns)
sns.boxplot(data=X)
plt.show()
X.head()

from sklearn.linear_model import Lasso, Ridge

ridge = Ridge(alpha=1.0)
ridge.fit(X, Y)
print("Ridge coefficients:", ridge.coef_)


lasso = Lasso(alpha=1.0)
lasso.fit(X, Y)
print("Lasso coefficients:", lasso.coef_)

from statsmodels.stats.outliers_influence import variance_inflation_factor as vif

vif_data = pd.DataFrame()
vif_data["features"] = X.columns
vif_data["VIF Factor"] = [vif(X.values, i) for i in range(X.shape[1])]

print(vif_data)

from sklearn.model_selection  import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3)

from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
x_train_scaled = scaler.fit_transform(x_train)

MNB = MultinomialNB()
MNB.fit(x_train_scaled, y_train)

y_pred_train = MNB.predict(x_train)
y_pred_test = MNB.predict(x_test)

from sklearn.metrics import r2_score, log_loss,accuracy_score


r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)

print("R2 score (train):", r2_train)
print("R2 score (test):", r2_test)

X

X = X.abs()
X.head()

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score

MNB = MultinomialNB()
MNB.fit(X, Y)

Y_pred = MNB.predict(X)

cm = confusion_matrix(Y, Y_pred)

print("Accuracy score:", accuracy_score(Y, Y_pred).round(2))
print("Sensitivity score:", recall_score(Y, Y_pred, average='macro').round(2))
print("Precision score:", precision_score(Y, Y_pred, average='macro').round(2))
print("F1 score:", f1_score(Y, Y_pred, average='macro').round(2))

TN = cm[0,0]
FP = cm[1,0]
TNR = TN / (FP + TN)
print("Specificity score:", TNR.round(2))

